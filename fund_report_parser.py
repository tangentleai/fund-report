#!/usr/bin/env python3
"""
åŸºé‡‘å­£æŠ¥è§£æ Demo
æå–åŸºé‡‘ç»ç†è§‚ç‚¹å¹¶è½¬æ¢ä¸ºæ’­å®¢è„šæœ¬
"""

import re
import json
import requests
from pathlib import Path
from typing import Optional, Dict, List, Any

# æµ‹è¯•ç”¨åŸºé‡‘åˆ—è¡¨
TEST_FUNDS = [
    {"code": "005827", "name": "æ˜“æ–¹è¾¾è“ç­¹ç²¾é€‰æ··åˆ", "manager": "å¼ å¤"},
    {"code": "003095", "name": "ä¸­æ¬§åŒ»ç–—å¥åº·æ··åˆA", "manager": "è‘›å…°"},
    {"code": "161725", "name": "æ‹›å•†ä¸­è¯ç™½é…’æŒ‡æ•°", "manager": "ä¾¯æ˜Š"},
]


def download_fund_report(fund_code: str, fund_name: str) -> Optional[str]:
    """
    ä¸‹è½½åŸºé‡‘å­£æŠ¥PDF
    æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œå®é™…éœ€è¦ä»AKShareæˆ–å¤©å¤©åŸºé‡‘è·å–çœŸå®PDFé“¾æ¥
    """
    print(f"\nğŸ“¥ æ­£åœ¨è·å– {fund_name}({fund_code}) çš„å­£æŠ¥...")

    # æ¨¡æ‹ŸPDFä¸‹è½½ï¼ˆå®é™…é¡¹ç›®ä¸­ä½¿ç”¨AKShareè·å–çœŸå®é“¾æ¥ï¼‰
    # è¿™é‡Œè¿”å›ç¤ºä¾‹æ–‡æœ¬ç”¨äºæµ‹è¯•è§£æé€»è¾‘
    return None


def parse_pdf_content(pdf_text: str) -> Dict[str, Any]:
    """
    è§£æPDFå†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯
    """
    result: Dict[str, Any] = {
        "fund_name": None,
        "report_date": None,
        "manager_viewpoint": None,
        "market_analysis": None,
        "future_outlook": None,
    }

    # 1. æå–åŸºé‡‘åç§°
    name_pattern = r"åŸºé‡‘ç®€ç§°[ï¼š:]\s*([^\n]+)"
    match = re.search(name_pattern, pdf_text)
    if match:
        result["fund_name"] = match.group(1).strip()

    # 2. æå–æŠ¥å‘Šæ—¥æœŸ
    date_patterns = [
        r"æŠ¥å‘ŠæœŸ[ï¼š:]\s*(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)",
        r"(\d{4})å¹´ç¬¬([ä¸€äºŒä¸‰å››])å­£åº¦æŠ¥å‘Š",
        r"æˆªè‡³\s*(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)",
    ]
    for pattern in date_patterns:
        match = re.search(pattern, pdf_text)
        if match:
            result["report_date"] = match.group(0)
            break

    # 3. æå–åŸºé‡‘ç»ç†è§‚ç‚¹ - æ ¸å¿ƒé€»è¾‘
    viewpoint = extract_manager_viewpoint(pdf_text)
    result["manager_viewpoint"] = viewpoint

    return result


def extract_manager_viewpoint(text: str) -> Optional[str]:
    """
    æå–åŸºé‡‘ç»ç†è§‚ç‚¹ç« èŠ‚
    å­£æŠ¥ç»“æ„ç›¸å¯¹å›ºå®šï¼Œé‡ç‚¹æå–"æŠ•èµ„ç­–ç•¥å’Œè¿ä½œåˆ†æ"éƒ¨åˆ†
    """
    # æ¸…ç†æ–‡æœ¬
    text = clean_text(text)

    # å¤šç§åŒ¹é…æ¨¡å¼ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
    patterns = [
        # æ¨¡å¼1: ç²¾ç¡®åŒ¹é…"æŠ¥å‘ŠæœŸå†…åŸºé‡‘æŠ•èµ„ç­–ç•¥å’Œè¿ä½œåˆ†æ"
        r"æŠ¥å‘ŠæœŸå†…åŸºé‡‘æŠ•èµ„ç­–ç•¥å’Œè¿ä½œåˆ†æ\s*[ï¼š:]?\s*\n?\s*([^Â§]+?)(?=\s*(?:Â§|ç¬¬[äº”å…­ä¸ƒå…«]èŠ‚|ç¬¬äº”èŠ‚|é‡è¦æç¤º|æŠ•èµ„ç»„åˆæŠ¥å‘Š|æŠ¥å‘ŠæœŸå†…åŸºé‡‘çš„ä¸šç»©è¡¨ç°|åŸºé‡‘çš„ä¸šç»©è¡¨ç°|åŸºé‡‘æŒæœ‰äººæ•°|åŸºé‡‘èµ„äº§å‡€å€¼é¢„è­¦|é‡å¤§äº‹é¡¹æç¤º|è´¢åŠ¡æŒ‡æ ‡))",
        # æ¨¡å¼2: åŒ¹é…"æŠ•èµ„ç­–ç•¥å’Œè¿ä½œåˆ†æ"é•¿æ®µè½
        r"æŠ•èµ„ç­–ç•¥å’Œè¿ä½œåˆ†æ\s*[ï¼š:]?\s*([\s\S]{200,4000}?)(?=\s*(?:Â§|ç¬¬[äº”å…­ä¸ƒå…«]èŠ‚|ç¬¬äº”èŠ‚|é‡è¦æç¤º|æŠ•èµ„ç»„åˆæŠ¥å‘Š|æŠ¥å‘ŠæœŸå†…åŸºé‡‘çš„ä¸šç»©è¡¨ç°|åŸºé‡‘çš„ä¸šç»©è¡¨ç°|åŸºé‡‘æŒæœ‰äººæ•°|åŸºé‡‘èµ„äº§å‡€å€¼é¢„è­¦|é‡å¤§äº‹é¡¹æç¤º|è´¢åŠ¡æŒ‡æ ‡))",
        # æ¨¡å¼3: åŒ¹é…"ç®¡ç†äººæŠ¥å‘Š"ä¸‹çš„å†…å®¹
        r"ç®¡ç†äººæŠ¥å‘Š.*?åŸºé‡‘ç»ç†.*?\n\s*([^Â§]+?)(?=\s*(?:Â§|ç¬¬[äº”å…­]èŠ‚|æŠ¥å‘ŠæœŸå†…åŸºé‡‘çš„ä¸šç»©è¡¨ç°|åŸºé‡‘çš„ä¸šç»©è¡¨ç°|åŸºé‡‘æŒæœ‰äººæ•°|åŸºé‡‘èµ„äº§å‡€å€¼é¢„è­¦|é‡å¤§äº‹é¡¹æç¤º|è´¢åŠ¡æŒ‡æ ‡))",
        # æ¨¡å¼4: åŒ¹é…"4\.1"æˆ–"4.2"åŸºé‡‘ç®¡ç†äººè¿ç”¨å›ºæœ‰èµ„é‡‘æŠ•èµ„æƒ…å†µå‰çš„å†…å®¹
        r"4\.\d+\s*åŸºé‡‘ç®¡ç†äºº.*?\n\s*([\s\S]{200,3000}?)(?=4\.\d+|Â§|ç¬¬[äº”å…­]èŠ‚|æŠ¥å‘ŠæœŸå†…åŸºé‡‘çš„ä¸šç»©è¡¨ç°|åŸºé‡‘çš„ä¸šç»©è¡¨ç°|åŸºé‡‘æŒæœ‰äººæ•°|åŸºé‡‘èµ„äº§å‡€å€¼é¢„è­¦|é‡å¤§äº‹é¡¹æç¤º|è´¢åŠ¡æŒ‡æ ‡)",
    ]

    for pattern in patterns:
        match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
        if match:
            viewpoint = match.group(1).strip()
            # è¿›ä¸€æ­¥æ¸…æ´—
            viewpoint = post_clean(viewpoint)
            if validate_viewpoint(viewpoint):
                return viewpoint

    # å¦‚æœéƒ½æ²¡åŒ¹é…åˆ°ï¼Œå°è¯•å…œåº•æ–¹æ¡ˆï¼šæ‰¾å¤§æ®µè¿ç»­çš„æŠ•èµ„ç›¸å…³æ–‡æœ¬
    fallback = fallback_extract(text)
    if not fallback:
        return None
    fallback = post_clean(fallback)
    return fallback if validate_viewpoint(fallback) else None


def clean_text(text: str) -> str:
    """æ–‡æœ¬é¢„å¤„ç†"""
    # ç»Ÿä¸€æ¢è¡Œç¬¦
    text = text.replace("\r\n", "\n").replace("\r", "\n")

    # å»æ‰é¡µçœ‰é¡µè„š (å¦‚ "ç¬¬ X é¡µ å…± Y é¡µ")
    text = re.sub(r"ç¬¬\s*\d+\s*é¡µ\s*å…±\s*\d+\s*é¡µ", "", text)
    text = re.sub(r"Page\s*\d+\s*of\s*\d+", "", text, flags=re.IGNORECASE)

    # å»æ‰é¡µç  (å¦‚ "- 3 -" æˆ– "â€”3â€”")
    text = re.sub(r"[\-â€“â€”]\s*\d+\s*[\-â€“â€”]", "", text)

    # åˆå¹¶å•è¡Œæ¢è¡Œï¼Œä¿ç•™æ®µè½æ¢è¡Œ
    text = re.sub(r"(?<!\n)\n(?!\n)", " ", text)
    text = re.sub(r" +", " ", text)

    # åˆå¹¶å¤šä¸ªæ¢è¡Œ
    text = re.sub(r"\n{3,}", "\n\n", text)

    return text.strip()


def post_clean(text: str) -> str:
    """è§‚ç‚¹æå–åæ¸…æ´—"""
    # å»æ‰å¸¸è§çš„åºŸè¯å¼€å¤´
    useless_prefixes = [
        "æŠ¥å‘ŠæœŸå†…ï¼Œ",
        "æœ¬æŠ¥å‘ŠæœŸå†…ï¼Œ",
        "æœ¬åŸºé‡‘",
        "2024å¹´",
    ]
    for prefix in useless_prefixes:
        if text.startswith(prefix):
            text = text[len(prefix) :].strip()

    # å»æ‰è¡¨æ ¼æ®‹ç•™
    text = re.sub(r"\|\s*[^\|]+\s*\|", "", text)

    # å»æ‰åŸºé‡‘ç»ç†ç®€ä»‹ç­‰å™ªéŸ³
    noise_patterns = [
        r"å§“å\s+\w+\s+èŒåŠ¡\s+åŸºé‡‘ç»ç†",
        r"4\.\d+\s*åŸºé‡‘ç»ç†.*?ç®€ä»‹",
        r"4\.\d+\s*ç®¡ç†äººå¯¹æŠ¥å‘ŠæœŸå†….*?è¯´æ˜",
        r"æŠ•èµ„ç­–ç•¥å’Œè¿ä½œåˆ†æ\s*[ï¼š:]?\s*\n?",
        r"[\u4e00-\u9fffA-Za-z0-9ï¼ˆï¼‰()Â·\-]{6,}è¯åˆ¸æŠ•èµ„åŸºé‡‘\d{4}å¹´ç¬¬[ä¸€äºŒä¸‰å››1234]å­£åº¦æŠ¥å‘Š",
        r"[\u4e00-\u9fffA-Za-z0-9ï¼ˆï¼‰()Â·\-]{6,}è¯åˆ¸æŠ•èµ„åŸºé‡‘\d{4}å¹´ä¸­æœŸæŠ¥å‘Š",
        r"[\u4e00-\u9fffA-Za-z0-9ï¼ˆï¼‰()Â·\-]{6,}è¯åˆ¸æŠ•èµ„åŸºé‡‘\d{4}å¹´åº¦æŠ¥å‘Š",
    ]
    for pattern in noise_patterns:
        text = re.sub(pattern, "", text, flags=re.IGNORECASE)

    stop_pattern = (
        r"(æŠ¥å‘ŠæœŸå†…åŸºé‡‘çš„ä¸šç»©è¡¨ç°|åŸºé‡‘çš„ä¸šç»©è¡¨ç°|åŸºé‡‘æŒæœ‰äººæ•°|åŸºé‡‘èµ„äº§å‡€å€¼é¢„è­¦"
        r"|é‡å¤§äº‹é¡¹æç¤º|è´¢åŠ¡æŒ‡æ ‡|æŠ•èµ„ç»„åˆæŠ¥å‘Š|è´¢åŠ¡ä¼šè®¡æŠ¥å‘Š)"
    )
    text = re.split(stop_pattern, text, maxsplit=1)[0]
    text = re.sub(r"(4\.\d+|ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«]èŠ‚)\s*$", "", text).strip()

    # æ¸…ç†è¡Œ
    lines = text.split("\n")
    cleaned_lines = []
    for line in lines:
        line = line.strip()
        # è¿‡æ»¤æ‰å¤ªçŸ­çš„è¡Œ
        if len(line) < 3:
            continue
        # è¿‡æ»¤æ‰åªæœ‰æ•°å­—æˆ–æ ‡ç‚¹çš„è¡Œ
        if re.match(r"^[\d\s\.\-â€”]+$", line):
            continue
        # è¿‡æ»¤æ‰åŸºé‡‘ç»ç†ä¿¡æ¯è¡Œ
        if re.match(r"^å§“å|èŒåŠ¡|åŸºé‡‘ç»ç†", line):
            continue
        # ä¿ç•™æœ‰å®è´¨å†…å®¹çš„è¡Œ
        if len(line) > 10 or re.search(r"[\u4e00-\u9fff]{3,}", line):
            cleaned_lines.append(line)

    result = "\n".join(cleaned_lines).strip()

    # æœ€ç»ˆæ¸…ç†
    result = re.sub(r"\n{3,}", "\n\n", result)

    return result


def validate_viewpoint(text: str) -> bool:
    """éªŒè¯æå–çš„è§‚ç‚¹æ˜¯å¦æœ‰æ•ˆ"""
    if not text or len(text) < 50:
        return False

    # æ£€æŸ¥æ˜¯å¦åŒ…å«æŠ•èµ„ç›¸å…³å…³é”®è¯
    investment_keywords = [
        "å¸‚åœº",
        "è¡Œä¸š",
        "é…ç½®",
        "æŠ•èµ„",
        "ç­–ç•¥",
        "é£é™©",
        "æœºä¼š",
        "è‚¡ç¥¨",
        "å€ºåˆ¸",
        "ä»“ä½",
        "ä¼°å€¼",
        "ç›ˆåˆ©",
        "å¢é•¿",
        "ç»æµ",
    ]

    keyword_count = sum(1 for kw in investment_keywords if kw in text)
    return keyword_count >= 2  # è‡³å°‘åŒ…å«2ä¸ªæŠ•èµ„å…³é”®è¯


def fallback_extract(text: str) -> Optional[str]:
    """å…œåº•æå–æ–¹æ¡ˆ"""
    # æŸ¥æ‰¾åŒ…å«æŠ•èµ„å…³é”®è¯çš„æœ€é•¿è¿ç»­æ®µè½
    paragraphs = re.split(r"\n{2,}", text)

    best_paragraph = None
    best_score = 0

    for para in paragraphs:
        if len(para) < 100 or len(para) > 5000:
            continue

        # è¯„åˆ†ï¼šåŒ…å«çš„æŠ•èµ„å…³é”®è¯è¶Šå¤šã€æ–‡æœ¬è¶Šé•¿ï¼Œåˆ†æ•°è¶Šé«˜
        score = len(para)
        investment_keywords = ["ç­–ç•¥", "æŠ•èµ„", "å¸‚åœº", "é…ç½®", "è¡Œä¸š", "é£é™©"]
        score += sum(50 for kw in investment_keywords if kw in para)

        if score > best_score:
            best_score = score
            best_paragraph = para

    return best_paragraph.strip() if best_paragraph else None


def generate_podcast_script(viewpoint: str, fund_name: str, manager: str) -> str:
    """
    å°†åŸºé‡‘ç»ç†è§‚ç‚¹è½¬æ¢ä¸ºæ’­å®¢å¯¹è¯è„šæœ¬
    """
    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥è°ƒç”¨AIæ¨¡å‹
    script = f"""
ã€æ’­å®¢è„šæœ¬ã€‘{fund_name} å­£æŠ¥è§£è¯»

ä¸»æŒäººå°æ˜ï¼šå¤§å®¶å¥½ï¼Œæ¬¢è¿æ”¶å¬æœ¬æœŸåŸºé‡‘å­£æŠ¥è§£è¯»ã€‚ä»Šå¤©æˆ‘ä»¬èŠçš„æ˜¯{fund_name}ï¼ŒåŸºé‡‘ç»ç†æ˜¯{manager}ã€‚

ä¸»æŒäººå°çº¢ï¼šå…ˆæ¥çœ‹åŸºé‡‘ç»ç†åœ¨æœ€æ–°å­£æŠ¥ä¸­çš„è§‚ç‚¹ï¼š

{viewpoint[:500]}...

ä¸»æŒäººå°æ˜ï¼šä»è¿™æ®µè¯å¯ä»¥çœ‹å‡ºï¼ŒåŸºé‡‘ç»ç†å¯¹åå¸‚çš„æ€åº¦...

ä¸»æŒäººå°çº¢ï¼šé‚£æˆ‘ä»¬å¯¹æ™®é€šæŠ•èµ„è€…æœ‰ä»€ä¹ˆå»ºè®®å‘¢ï¼Ÿ
...
"""
    return script


def test_with_sample():
    """ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•è§£æé€»è¾‘"""

    # æ¨¡æ‹Ÿå­£æŠ¥æ–‡æœ¬ï¼ˆå®é™…æ˜¯ä»PDFæå–çš„ï¼‰
    sample_report = """
æ˜“æ–¹è¾¾è“ç­¹ç²¾é€‰æ··åˆå‹è¯åˆ¸æŠ•èµ„åŸºé‡‘
2024å¹´ç¬¬4å­£åº¦æŠ¥å‘Š

Â§1 é‡è¦æç¤º
åŸºé‡‘ç®¡ç†äººçš„è‘£äº‹ä¼šåŠè‘£äº‹ä¿è¯æœ¬æŠ¥å‘Šæ‰€è½½èµ„æ–™ä¸å­˜åœ¨è™šå‡è®°è½½...

Â§4 ç®¡ç†äººæŠ¥å‘Š
4.1 åŸºé‡‘ç»ç†(æˆ–åŸºé‡‘ç»ç†å°ç»„)ç®€ä»‹
å§“å å¼ å¤ èŒåŠ¡ åŸºé‡‘ç»ç†

4.2 ç®¡ç†äººå¯¹æŠ¥å‘ŠæœŸå†…æœ¬åŸºé‡‘æŠ•èµ„ç­–ç•¥å’Œè¿ä½œåˆ†æçš„è¯´æ˜

æŠ¥å‘ŠæœŸå†…ï¼ŒAè‚¡å¸‚åœºå‘ˆç°éœ‡è¡èµ°åŠ¿ï¼Œæ²ªæ·±300æŒ‡æ•°ä¸Šæ¶¨...æœ¬åŸºé‡‘ä¿æŒè¾ƒé«˜çš„è‚¡ç¥¨ä»“ä½ï¼Œé‡ç‚¹é…ç½®äº†æ¶ˆè´¹ã€åŒ»è¯ç­‰è¡Œä¸šçš„ä¼˜è´¨ä¼ä¸šã€‚

ä»é•¿æœŸçœ‹ï¼Œä¸­å›½ç»æµçš„åŸºæœ¬é¢ä¾ç„¶ç¨³å›ºï¼Œä¼˜è´¨ä¼ä¸šçš„æŠ¤åŸæ²³ä»åœ¨åŠ æ·±ã€‚æˆ‘ä»¬è®¤ä¸ºå½“å‰å¸‚åœºçš„ä¼°å€¼æ°´å¹³å¤„äºå†å²è¾ƒä½ä½ç½®ï¼Œä¸ºé•¿æœŸæŠ•èµ„è€…æä¾›äº†è¾ƒå¥½çš„å¸ƒå±€æœºä¼šã€‚

åœ¨æ“ä½œä¸Šï¼Œæœ¬åŸºé‡‘ç»´æŒäº†å¯¹ä¼˜è´¨ä¼ä¸šçš„é•¿æœŸæŒæœ‰ï¼Œå¹¶æ ¹æ®åŸºæœ¬é¢å˜åŒ–è¿›è¡Œäº†é€‚åº¦è°ƒæ•´ã€‚

Â§5 æŠ•èµ„ç»„åˆæŠ¥å‘Š
5.1 æŠ¥å‘ŠæœŸæœ«åŸºé‡‘èµ„äº§ç»„åˆæƒ…å†µ
...
"""

    print("=" * 60)
    print("ğŸ§ª æµ‹è¯•åŸºé‡‘å­£æŠ¥è§£æ")
    print("=" * 60)

    result = parse_pdf_content(sample_report)

    print(f"\nâœ… è§£æç»“æœï¼š")
    print(f"   åŸºé‡‘åç§°: {result['fund_name']}")
    print(f"   æŠ¥å‘Šæ—¥æœŸ: {result['report_date']}")
    print(f"\nğŸ“ åŸºé‡‘ç»ç†è§‚ç‚¹:")
    print(
        f"   {result['manager_viewpoint'][:300]}..."
        if result["manager_viewpoint"]
        else "   æœªæå–åˆ°è§‚ç‚¹"
    )

    if result["manager_viewpoint"]:
        print(f"\nğŸ™ï¸  æ’­å®¢è„šæœ¬é¢„è§ˆ:")
        script = generate_podcast_script(
            result["manager_viewpoint"], "æ˜“æ–¹è¾¾è“ç­¹ç²¾é€‰æ··åˆ", "å¼ å¤"
        )
        print(script[:500] + "...")

    return result


def test_real_fund(fund_code: str, fund_name: str, manager: str):
    """
    æµ‹è¯•çœŸå®åŸºé‡‘æ•°æ®ï¼ˆéœ€è¦AKShareï¼‰
    """
    try:
        import akshare as ak

        print(f"\n{'=' * 60}")
        print(f"ğŸ” è·å–çœŸå®æ•°æ®: {fund_name}({fund_code})")
        print(f"{'=' * 60}")

        # è·å–åŸºé‡‘å…¬å‘Šåˆ—è¡¨
        try:
            announcement_df = ak.fund_announcement_personnel_em(symbol=fund_code)
            print(f"âœ… æˆåŠŸè·å–å…¬å‘Šåˆ—è¡¨ï¼Œå…± {len(announcement_df)} æ¡")
            print(f"\næœ€è¿‘å‡ æ¡å…¬å‘Šï¼š")
            print(announcement_df.head(3)[["åç§°", "å‘å¸ƒæ—¶é—´"]].to_string(index=False))
        except Exception as e:
            print(f"âš ï¸  è·å–å…¬å‘Šåˆ—è¡¨å¤±è´¥: {e}")
            return None

        # æ³¨æ„ï¼šå®é™…PDFä¸‹è½½éœ€è¦è§£æå…¬å‘Šé“¾æ¥
        print(f"\nğŸ’¡ æç¤º: å®é™…é¡¹ç›®ä¸­éœ€è¦ä»å…¬å‘Šé“¾æ¥ä¸‹è½½PDFå¹¶è§£æ")

    except ImportError:
        print("âŒ æœªå®‰è£… AKShareï¼Œè¯·è¿è¡Œ: pip install akshare")
        return None

    return None


if __name__ == "__main__":
    # 1. å…ˆç”¨æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•è§£æé€»è¾‘
    print("\n" + "=" * 60)
    print("ç¬¬ä¸€æ­¥ï¼šæµ‹è¯•è§£æé€»è¾‘")
    print("=" * 60)
    test_with_sample()

    # 2. å°è¯•è·å–çœŸå®æ•°æ®ï¼ˆå¦‚æœå®‰è£…äº†AKShareï¼‰
    print("\n" + "=" * 60)
    print("ç¬¬äºŒæ­¥ï¼šæµ‹è¯•çœŸå®æ•°æ®è·å–")
    print("=" * 60)

    try:
        test_real_fund("005827", "æ˜“æ–¹è¾¾è“ç­¹ç²¾é€‰æ··åˆ", "å¼ å¤")
    except Exception as e:
        print(f"âš ï¸  çœŸå®æ•°æ®æµ‹è¯•è·³è¿‡: {e}")

    print("\n" + "=" * 60)
    print("âœ¨ Demo å®Œæˆï¼")
    print("=" * 60)
    print("\nä¸‹ä¸€æ­¥å»ºè®®ï¼š")
    print("1. å®‰è£… AKShare: pip install akshare")
    print("2. å®ç°çœŸå®PDFä¸‹è½½é€»è¾‘")
    print("3. æ¥å…¥AIæ¨¡å‹ç”Ÿæˆæ’­å®¢è„šæœ¬")
    print("4. é›†æˆTTSç”ŸæˆéŸ³é¢‘")
