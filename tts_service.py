#!/usr/bin/env python3
"""
TTSæœåŠ¡ - MVPç‰ˆæœ¬
ä½¿ç”¨Edge TTSï¼ˆå…è´¹ï¼‰å¿«é€ŸéªŒè¯ï¼Œé¢„ç•™å•†ä¸šTTSåˆ‡æ¢æ¥å£
"""

import asyncio
import edge_tts
from pathlib import Path
from typing import List, Dict, Optional
from dataclasses import dataclass
import logging
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class DialogueSegment:
    """å¯¹è¯ç‰‡æ®µ"""

    speaker: str  # "å°æ˜" æˆ– "å°çº¢"
    text: str
    start_time: float = 0.0  # åœ¨æœ€ç»ˆéŸ³é¢‘ä¸­çš„èµ·å§‹æ—¶é—´


class TTSService:
    """
    TTSæœåŠ¡åŸºç±»
    é¢„ç•™æ¥å£ï¼Œæ–¹ä¾¿åæœŸåˆ‡æ¢åˆ°å•†ä¸šTTS
    """

    async def generate(self, text: str, voice: str, output_path: str) -> bool:
        """ç”ŸæˆéŸ³é¢‘"""
        raise NotImplementedError

    async def generate_dialogue(
        self, segments: List[DialogueSegment], output_path: str
    ) -> Optional[Dict]:
        """ç”Ÿæˆå¯¹è¯éŸ³é¢‘"""
        raise NotImplementedError


class EdgeTTSService(TTSService):
    """
    Edge TTS å®ç°ï¼ˆMVPé˜¶æ®µä½¿ç”¨ï¼‰
    åŸºäºå¾®è½¯Edgeæµè§ˆå™¨çš„æœ—è¯»åŠŸèƒ½
    """

    # å£°éŸ³é…ç½®
    VOICES = {
        "male": "zh-CN-YunxiNeural",  # å°æ˜ - ç”·å£°ï¼Œçƒ­æƒ…è‡ªç„¶
        "female": "zh-CN-XiaoxiaoNeural",  # å°çº¢ - å¥³å£°ï¼Œäº²åˆ‡è‡ªç„¶
        "male_alt": "zh-CN-YunjianNeural",  # å¤‡é€‰ç”·å£°
        "female_alt": "zh-CN-XiaoyiNeural",  # å¤‡é€‰å¥³å£°
    }

    def __init__(self, rate_limit: int = 5):
        """
        Args:
            rate_limit: æ¯åˆ†é’Ÿæœ€å¤§è¯·æ±‚æ•°ï¼Œé˜²æ­¢è¢«å°
        """
        self.rate_limit = rate_limit
        self.request_count = 0
        self.last_reset = datetime.now()

    async def _check_rate_limit(self):
        """ç®€å•çš„é€Ÿç‡é™åˆ¶"""
        now = datetime.now()
        if (now - self.last_reset).seconds >= 60:
            self.request_count = 0
            self.last_reset = now

        if self.request_count >= self.rate_limit:
            wait_time = 60 - (now - self.last_reset).seconds
            if wait_time > 0:
                logger.warning(f"è§¦å‘é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’")
                await asyncio.sleep(wait_time)
                self.request_count = 0
                self.last_reset = datetime.now()

    async def generate(
        self, text: str, voice: str = "male", output_path: str = None
    ) -> Optional[str]:
        """
        ç”Ÿæˆå•æ®µéŸ³é¢‘

        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            voice: å£°éŸ³ç±»å‹ (male/female)
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Returns:
            æˆåŠŸè¿”å›æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        await self._check_rate_limit()

        if output_path is None:
            output_path = f"/tmp/tts_{hash(text)}.mp3"

        voice_name = self.VOICES.get(voice, self.VOICES["male"])

        try:
            communicate = edge_tts.Communicate(text, voice_name)
            await communicate.save(output_path)
            self.request_count += 1
            logger.info(f"âœ… TTSç”ŸæˆæˆåŠŸ: {output_path}")
            return output_path
        except Exception as e:
            logger.error(f"âŒ TTSç”Ÿæˆå¤±è´¥: {e}")
            return None

    async def generate_dialogue(
        self, segments: List[DialogueSegment], output_path: str = "output.mp3"
    ) -> Optional[Dict]:
        """
        ç”Ÿæˆå¯¹è¯éŸ³é¢‘ï¼ˆå¤šè§’è‰²ï¼‰

        Args:
            segments: å¯¹è¯ç‰‡æ®µåˆ—è¡¨
            output_path: æœ€ç»ˆéŸ³é¢‘è¾“å‡ºè·¯å¾„

        Returns:
            åŒ…å«éŸ³é¢‘è·¯å¾„å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        if not segments:
            logger.error("å¯¹è¯ç‰‡æ®µä¸ºç©º")
            return None

        temp_files = []
        transcripts = []
        current_time = 0.0

        try:
            # 1. ä¸ºæ¯ä¸ªç‰‡æ®µç”ŸæˆéŸ³é¢‘
            for i, segment in enumerate(segments):
                voice = "male" if segment.speaker == "å°æ˜" else "female"
                temp_path = f"/tmp/dialogue_{i}_{hash(segment.text)}.mp3"

                result = await self.generate(segment.text, voice, temp_path)
                if result:
                    temp_files.append(result)
                    duration = self._get_audio_duration(result) or len(segment.text) / 3.5
                    transcripts.append(
                        {
                            "time": round(current_time, 1),
                            "speaker": segment.speaker,
                            "text": segment.text,
                        }
                    )
                    current_time += duration
                else:
                    logger.warning(f"ç‰‡æ®µ {i} ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡")

            # 2. åˆå¹¶éŸ³é¢‘ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…åº”è¯¥ç”¨ffmpegæˆ–pydubï¼‰
            await self._merge_audio_files(temp_files, output_path)

            # 3. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for temp_file in temp_files:
                try:
                    Path(temp_file).unlink()
                except:
                    pass

            return {
                "audio_path": output_path,
                "duration": round(current_time, 1),
                "transcript": transcripts,
                "format": "mp3",
            }

        except Exception as e:
            logger.error(f"å¯¹è¯ç”Ÿæˆå¤±è´¥: {e}")
            return None

    async def _merge_audio_files(self, files: List[str], output: str):
        try:
            from pydub import AudioSegment

            combined = AudioSegment.empty()
            for file in files:
                audio = AudioSegment.from_mp3(file)
                combined += audio

            combined.export(output, format="mp3")
            logger.info(f"âœ… éŸ³é¢‘åˆå¹¶å®Œæˆ: {output}")
            return
        except Exception:
            pass

        import shutil
        import subprocess

        ffmpeg = shutil.which("ffmpeg")
        if ffmpeg and files:
            list_file = Path(output).with_suffix(".txt")
            list_content = "".join([f"file '{file}'\n" for file in files])
            list_file.write_text(list_content, encoding="utf-8")
            try:
                subprocess.run(
                    [
                        ffmpeg,
                        "-y",
                        "-f",
                        "concat",
                        "-safe",
                        "0",
                        "-i",
                        str(list_file),
                        "-c:a",
                        "libmp3lame",
                        "-q:a",
                        "2",
                        output,
                    ],
                    check=True,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                )
                if Path(output).exists():
                    list_file.unlink(missing_ok=True)
                    return
            except Exception:
                list_file.unlink(missing_ok=True)

        if files:
            shutil.copy(files[0], output)

    def _get_audio_duration(self, file_path: str) -> Optional[float]:
        try:
            from pydub import AudioSegment

            audio = AudioSegment.from_mp3(file_path)
            return len(audio) / 1000.0
        except Exception:
            return None


class AzureTTSService(TTSService):
    """
    Azure TTS å®ç°ï¼ˆç”Ÿäº§ç¯å¢ƒä½¿ç”¨ï¼‰
    é¢„ç•™æ¥å£ï¼ŒMVPåå†å®ç°
    """

    def __init__(self, subscription_key: str, region: str):
        self.subscription_key = subscription_key
        self.region = region
        # TODO: å®ç°Azure TTS
        pass

    async def generate(self, text: str, voice: str, output_path: str) -> bool:
        # TODO: å®ç°Azure TTS
        raise NotImplementedError("Azure TTSå°šæœªå®ç°")


# ============ ä½¿ç”¨ç¤ºä¾‹ ============


async def demo():
    """æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨TTSæœåŠ¡"""

    print("=" * 60)
    print("ğŸ™ï¸  Edge TTS æ¼”ç¤º")
    print("=" * 60)

    # åˆå§‹åŒ–æœåŠ¡
    tts = EdgeTTSService(rate_limit=10)

    # ç¤ºä¾‹1ï¼šå•æ®µéŸ³é¢‘
    print("\n1ï¸âƒ£  ç”Ÿæˆå•æ®µéŸ³é¢‘...")
    result = await tts.generate(
        text="å¤§å®¶å¥½ï¼Œæ¬¢è¿æ”¶å¬æœ¬æœŸåŸºé‡‘å­£æŠ¥è§£è¯»ã€‚",
        voice="male",
        output_path="demo_single.mp3",
    )
    if result:
        print(f"   âœ… å·²ä¿å­˜: {result}")

    # ç¤ºä¾‹2ï¼šå¤šè§’è‰²å¯¹è¯
    print("\n2ï¸âƒ£  ç”Ÿæˆæ’­å®¢å¯¹è¯...")
    dialogue = [
        DialogueSegment("å°æ˜", "å¤§å®¶å¥½ï¼Œä»Šå¤©æˆ‘ä»¬èŠä¸€ä¸‹æ˜“æ–¹è¾¾è“ç­¹åŸºé‡‘2024å¹´å››å­£æŠ¥ã€‚"),
        DialogueSegment("å°çº¢", "å¼ å¤è¿™å­£åº¦è¯´äº†ä»€ä¹ˆé‡ç‚¹å‘¢ï¼Ÿ"),
        DialogueSegment(
            "å°æ˜", "ä»–è¯´ä¸»è¦çœ‹å¥½æ¶ˆè´¹å’ŒåŒ»è¯æ¿å—ï¼Œè®¤ä¸ºå½“å‰ä¼°å€¼å¤„äºå†å²ä½ä½ã€‚"
        ),
        DialogueSegment("å°çº¢", "é‚£å¯¹æˆ‘ä»¬æ™®é€šæŠ•èµ„è€…æœ‰ä»€ä¹ˆå»ºè®®å—ï¼Ÿ"),
        DialogueSegment("å°æ˜", "å»ºè®®ä¿æŒé•¿æœŸæŒæœ‰ï¼Œä¸è¦è¢«çŸ­æœŸæ³¢åŠ¨å½±å“ã€‚"),
    ]

    result = await tts.generate_dialogue(
        segments=dialogue, output_path="demo_podcast.mp3"
    )

    if result:
        print(f"\nâœ… æ’­å®¢ç”ŸæˆæˆåŠŸï¼")
        print(f"   æ–‡ä»¶: {result['audio_path']}")
        print(f"   æ—¶é•¿: {result['duration']}ç§’")
        print(f"\nğŸ“„ æ–‡å­—ç¨¿:")
        for item in result["transcript"]:
            print(
                f"   [{item['time']:>5.1f}s] {item['speaker']}: {item['text'][:30]}..."
            )

    print("\n" + "=" * 60)
    print("âœ¨ æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)
    print("\nğŸ’¡ ç”Ÿäº§ç¯å¢ƒå»ºè®®ï¼š")
    print("   1. å®‰è£… pydub: pip install pydub")
    print("   2. å®‰è£… ffmpeg: brew install ffmpeg (Mac)")
    print("   3. å®ç° AzureTTSService ç”¨äºæ­£å¼ç¯å¢ƒ")


if __name__ == "__main__":
    asyncio.run(demo())
